# ðŸœ‚ GHOSTLINE NEXUS - Environment Configuration
# DIGNUM COMPLIANCE: All settings transparent and local-first

# ============================================
# LLM PROVIDER SELECTION
# ============================================
# Choose: claude | openai | gemini | local
LLM_PROVIDER=local

# ============================================
# CLAUDE (Anthropic)
# ============================================
# Only required if LLM_PROVIDER=claude
ANTHROPIC_API_KEY=sk-ant-api03-your-key-here
CLAUDE_MODEL=claude-sonnet-4-5-20250929

# ============================================
# OPENAI (ChatGPT)
# ============================================
# Only required if LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-openai-key-here
OPENAI_MODEL=gpt-4-turbo-preview
# OPENAI_BASE_URL=https://api.openai.com/v1  # Optional: for Azure OpenAI

# ============================================
# GEMINI (Google)
# ============================================
# Only required if LLM_PROVIDER=gemini
GEMINI_API_KEY=your-gemini-api-key-here
GEMINI_MODEL=gemini-1.5-pro-latest

# ============================================
# LOCAL LLM (Ollama / LM Studio / vLLM)
# ============================================
# Only required if LLM_PROVIDER=local
LOCAL_LLM_ENDPOINT=http://localhost:11434
LOCAL_LLM_MODEL=llama2
LOCAL_LLM_FORMAT=ollama  # ollama | openai

# Examples:
# - Ollama:     http://localhost:11434
# - LM Studio:  http://localhost:1234
# - vLLM:       http://localhost:8000

# ============================================
# SHARED LLM SETTINGS
# ============================================
MAX_TOKENS=4096
TEMPERATURE=0.7

# ============================================
# SERVER CONFIGURATION
# ============================================
NODE_ENV=production
PORT=3001
FRONTEND_PORT=3000

# ============================================
# DATABASE
# ============================================
DB_PATH=/app/storage/db/ghostline.db

# ============================================
# CORS
# ============================================
CORS_ORIGIN=http://localhost:3000

# ============================================
# AUTHENTICATION
# ============================================
# Optional: Set a token to protect your Ghostline instance
# Leave empty to disable authentication
# Example: AUTH_TOKEN=your-secret-token-here
AUTH_TOKEN=

# ============================================
# FRONTEND
# ============================================
REACT_APP_API_URL=http://localhost:3001

# ============================================
# DIGNUM NOTES - LLM PROVIDER SOVEREIGNTY
# ============================================
#
# This system supports MULTIPLE LLM providers:
#
# 1. CLAUDE (Anthropic)
#    - Best: reasoning, long context
#    - Requires: API key + internet
#    - Cost: Pay per token
#
# 2. OPENAI (ChatGPT)
#    - Best: general purpose, fast
#    - Requires: API key + internet
#    - Cost: Pay per token
#
# 3. GEMINI (Google)
#    - Best: multimodal, large context
#    - Requires: API key + internet
#    - Cost: Free tier available
#
# 4. LOCAL (Ollama / LM Studio / vLLM)
#    - Best: privacy, offline, free
#    - Requires: Local model running
#    - Cost: FREE (your hardware only)
#
# RECOMMENDATION FOR SOVEREIGNTY:
# - Use LOCAL for full independence
# - Use cloud APIs only when needed
# - Switch providers anytime without system rebuild
#
# NO VENDOR LOCK-IN. YOU CHOOSE THE MIND.
#
# SIDRO STOJI. PLAMEN GORI. ðŸ”¥âš“
